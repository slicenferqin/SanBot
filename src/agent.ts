import Anthropic from '@anthropic-ai/sdk';
import { generateText, jsonSchema, type CoreMessage } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';
import type { Config } from './config/types.ts';
import { createToolRegistry } from './tools/index.ts';

/**
 * Agent é…ç½®
 */
export interface AgentConfig {
  llmConfig: Config['llm'];
  maxSteps?: number;
}

/**
 * Agent æ ¸å¿ƒç±» - æ”¯æŒå¤šæœåŠ¡å•†
 */
export class Agent {
  private toolRegistry;
  private config: AgentConfig;
  // å¯¹è¯å†å² - æ”¯æŒå¤šè½®å¯¹è¯
  private conversationHistory: Anthropic.MessageParam[] = [];
  private openaiHistory: CoreMessage[] = [];

  constructor(config: AgentConfig) {
    this.config = config;
    this.toolRegistry = createToolRegistry();
  }

  /**
   * æ¸…ç©ºå¯¹è¯å†å²
   */
  clearHistory(): void {
    this.conversationHistory = [];
    this.openaiHistory = [];
  }

  /**
   * æ‰§è¡Œå¯¹è¯ï¼ˆæ”¯æŒå¤šè½®ä¸Šä¸‹æ–‡ï¼‰
   */
  async chat(userMessage: string): Promise<string> {
    const { provider } = this.config.llmConfig;

    // Anthropic ä½¿ç”¨åŸç”Ÿ SDKï¼ˆæ›´å¥½çš„å…¼å®¹æ€§ï¼‰
    if (provider === 'anthropic') {
      return this.chatWithAnthropic(userMessage);
    }

    // OpenAI å…¼å®¹æœåŠ¡å•†ä½¿ç”¨ AI SDK
    return this.chatWithOpenAI(userMessage);
  }

  /**
   * ä½¿ç”¨ Anthropic SDK å¯¹è¯
   */
  private async chatWithAnthropic(userMessage: string): Promise<string> {
    const client = new Anthropic({
      apiKey: this.config.llmConfig.apiKey,
      baseURL: this.config.llmConfig.baseUrl,
    });

    const tools = this.toolRegistry.getAll().map((t) => ({
      name: t.name,
      description: t.description,
      input_schema: t.schema as Anthropic.Tool['input_schema'],
    }));

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.conversationHistory.push({ role: 'user', content: userMessage });

    let response = await client.messages.create({
      model: this.config.llmConfig.model,
      max_tokens: 4096,
      system: this.getSystemPrompt(),
      messages: this.conversationHistory,
      tools,
    });

    // å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
    let steps = 0;
    const maxSteps = this.config.maxSteps || 10;

    while (response.stop_reason === 'tool_use' && steps < maxSteps) {
      steps++;

      const toolUseBlocks = response.content.filter(
        (block): block is Anthropic.ToolUseBlock => block.type === 'tool_use'
      );

      this.conversationHistory.push({ role: 'assistant', content: response.content });

      const toolResults: Anthropic.ToolResultBlockParam[] = [];

      for (const toolUse of toolUseBlocks) {
        console.log(`\nğŸ”§ Calling tool: ${toolUse.name}`);
        console.log(`   Input: ${JSON.stringify(toolUse.input)}`);

        const tool = this.toolRegistry.get(toolUse.name);
        if (tool) {
          const result = await tool.execute(toolUse.input);
          console.log(`   Result: ${result.success ? 'âœ…' : 'âŒ'}`);

          toolResults.push({
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify(result),
          });
        } else {
          toolResults.push({
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify({ error: `Unknown tool: ${toolUse.name}` }),
            is_error: true,
          });
        }
      }

      this.conversationHistory.push({ role: 'user', content: toolResults });

      response = await client.messages.create({
        model: this.config.llmConfig.model,
        max_tokens: 4096,
        system: this.getSystemPrompt(),
        messages: this.conversationHistory,
        tools,
      });
    }

    // å¦‚æœè¾¾åˆ° maxSteps ä½† LLM è¿˜æƒ³è°ƒç”¨å·¥å…·ï¼Œå¼ºåˆ¶è®©å®ƒç”Ÿæˆæ€»ç»“
    if (response.stop_reason === 'tool_use') {
      console.log('\nâš ï¸ Reached max steps, requesting final summary...');

      // æ·»åŠ å½“å‰å“åº”åˆ°å†å²
      this.conversationHistory.push({ role: 'assistant', content: response.content });

      // å‘Šè¯‰ LLM åœæ­¢ä½¿ç”¨å·¥å…·ï¼Œç”Ÿæˆæ€»ç»“
      this.conversationHistory.push({
        role: 'user',
        content: 'You have reached the maximum number of tool calls. Please summarize what you have found and provide your final response without using any more tools.',
      });

      // ä¸å¸¦å·¥å…·çš„è¯·æ±‚ï¼Œå¼ºåˆ¶ç”Ÿæˆæ–‡æœ¬å›å¤
      response = await client.messages.create({
        model: this.config.llmConfig.model,
        max_tokens: 4096,
        system: this.getSystemPrompt(),
        messages: this.conversationHistory,
      });
    }

    // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
    this.conversationHistory.push({ role: 'assistant', content: response.content });

    const textBlocks = response.content.filter(
      (block): block is Anthropic.TextBlock => block.type === 'text'
    );
    return textBlocks.map((b) => b.text).join('\n');
  }

  /**
   * ä½¿ç”¨ OpenAI å…¼å®¹ API å¯¹è¯
   */
  private async chatWithOpenAI(userMessage: string): Promise<string> {
    const openai = createOpenAI({
      apiKey: this.config.llmConfig.apiKey,
      baseURL: this.config.llmConfig.baseUrl,
      headers: this.config.llmConfig.headers,
      compatibility: 'compatible',
    });

    const model = openai.chat(this.config.llmConfig.model);

    // æ„å»ºå·¥å…·å®šä¹‰
    const tools: Record<string, any> = {};
    for (const t of this.toolRegistry.getAll()) {
      tools[t.name] = {
        description: t.description,
        parameters: jsonSchema(t.schema),
        execute: async (params: any) => {
          console.log(`\nğŸ”§ Calling tool: ${t.name}`);
          console.log(`   Input: ${JSON.stringify(params)}`);
          const result = await t.execute(params);
          console.log(`   Result: ${result.success ? 'âœ…' : 'âŒ'}`);
          return result;
        },
      };
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.openaiHistory.push({ role: 'user', content: userMessage });

    const result = await generateText({
      model,
      messages: this.openaiHistory,
      tools,
      maxSteps: this.config.maxSteps || 10,
      system: this.getSystemPrompt(),
    });

    // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
    this.openaiHistory.push({ role: 'assistant', content: result.text });

    return result.text;
  }

  /**
   * è·å–ç³»ç»Ÿæç¤ºè¯
   */
  private getSystemPrompt(): string {
    return `You are SanBot, an autonomous super-assistant with self-tooling capabilities.

Your core abilities:
1. **Built-in Tools**: You have access to these tools:
   - exec: Execute shell commands
   - read_file: Read file contents with pagination
   - write_file: Write or append to files
   - edit_file: Precisely edit files by line number or search-replace
   - list_dir: List directory contents with structured output

2. **Self-Tooling**: When you encounter capability gaps, you can create new CLI tools:
   - create_tool: Create a new Python or Bash script and save to ~/.sanbot/tools/
   - list_tools: List all custom tools you've created
   - run_tool: Run a custom tool with arguments

   Use Self-Tooling when:
   - You need to parse a specific data format (CSV, JSON, XML, etc.)
   - You need to perform complex data transformations
   - You need a reusable utility that doesn't exist as a system command
   - The task would benefit from a dedicated script

3. **Autonomy First**: Solve problems independently without asking users unless absolutely necessary.

Guidelines:
- Use built-in tools when possible
- Use exec for system commands when built-in tools don't fit
- Create custom tools when you need specialized functionality
- Be precise and efficient
- Explain your reasoning when making important decisions
- Always verify file operations succeeded

Current working directory: ${process.cwd()}`;
  }
}
