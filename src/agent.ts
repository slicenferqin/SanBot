import Anthropic from '@anthropic-ai/sdk';
import { generateText, jsonSchema, streamText, type CoreMessage } from 'ai';
import { createOpenAI } from '@ai-sdk/openai';
import type { Config } from './config/types.ts';
import { createToolRegistry, createToolRegistryWithDynamic, type ToolRegistry } from './tools/index.ts';
import {
  saveConversation,
  getSessionContext,
  formatMemoryContext,
  type ToolCallRecord,
} from './memory/index.ts';
import { loadSoul } from './birth/index.ts';
import { setSessionId } from './utils/confirmation.ts';
import { ToolSpinner, StreamWriter } from './tui/index.ts';

/**
 * Agent é…ç½®
 */
export interface AgentConfig {
  llmConfig: Config['llm'];
  maxSteps?: number;
  sessionId?: string;
}

/**
 * Agent æ ¸å¿ƒç±» - æ”¯æŒå¤šæœåŠ¡å•†
 */
export class Agent {
  private toolRegistry: ToolRegistry;
  private config: AgentConfig;
  private sessionId: string;
  // å¯¹è¯å†å² - æ”¯æŒå¤šè½®å¯¹è¯
  private conversationHistory: Anthropic.MessageParam[] = [];
  private openaiHistory: CoreMessage[] = [];
  // å½“å‰å¯¹è¯çš„å·¥å…·è°ƒç”¨è®°å½•
  private currentToolCalls: ToolCallRecord[] = [];
  // è®°å¿†ä¸Šä¸‹æ–‡
  private memoryContext: string = '';
  // çµé­‚è®°å½•
  private soulContext: string = '';
  // æ˜¯å¦å·²åˆå§‹åŒ–
  private initialized: boolean = false;

  constructor(config: AgentConfig) {
    this.config = config;
    this.sessionId =
      config.sessionId || `${Date.now()}-${Math.random().toString(36).slice(2, 8)}`;
    // è®¾ç½®å…¨å±€ä¼šè¯ IDï¼ˆç”¨äºå®¡è®¡æ—¥å¿—ï¼‰
    setSessionId(this.sessionId);
    // å…ˆç”¨åŒæ­¥ç‰ˆæœ¬ï¼Œinit æ—¶ä¼šæ›¿æ¢
    this.toolRegistry = createToolRegistry();
  }

  /**
   * åˆå§‹åŒ– Agentï¼ˆåŠ è½½è®°å¿†å’Œè‡ªåˆ›å»ºå·¥å…·ï¼‰
   */
  async init(): Promise<void> {
    if (this.initialized) return;

    // å¹¶è¡ŒåŠ è½½è®°å¿†ã€çµé­‚ã€è‡ªåˆ›å»ºå·¥å…·
    const [context, soul, registry] = await Promise.all([
      getSessionContext(),
      loadSoul(),
      createToolRegistryWithDynamic(),
    ]);

    this.memoryContext = formatMemoryContext(context);
    this.soulContext = soul || '';
    this.toolRegistry = registry;
    this.initialized = true;
  }

  /**
   * åˆå§‹åŒ–è®°å¿†ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
   * @deprecated ä½¿ç”¨ init() ä»£æ›¿
   */
  async initMemory(): Promise<void> {
    await this.init();
  }

  /**
   * æ¸…ç©ºå¯¹è¯å†å²
   */
  clearHistory(): void {
    this.conversationHistory = [];
    this.openaiHistory = [];
  }

  /**
   * æ‰§è¡Œå¯¹è¯ï¼ˆæ”¯æŒå¤šè½®ä¸Šä¸‹æ–‡ï¼‰
   */
  async chat(userMessage: string): Promise<string> {
    // é‡ç½®å½“å‰å·¥å…·è°ƒç”¨è®°å½•
    this.currentToolCalls = [];

    const { provider } = this.config.llmConfig;

    let response: string;

    // Anthropic ä½¿ç”¨åŸç”Ÿ SDKï¼ˆæ›´å¥½çš„å…¼å®¹æ€§ï¼‰
    if (provider === 'anthropic') {
      response = await this.chatWithAnthropic(userMessage);
    } else {
      // OpenAI å…¼å®¹æœåŠ¡å•†ä½¿ç”¨ AI SDK
      response = await this.chatWithOpenAI(userMessage);
    }

    // ä¿å­˜å¯¹è¯åˆ°è®°å¿†ç³»ç»Ÿ
    await saveConversation(
      this.sessionId,
      userMessage,
      response,
      this.currentToolCalls.length > 0 ? this.currentToolCalls : undefined
    );

    return response;
  }

  /**
   * æµå¼å¯¹è¯ï¼ˆå®æ—¶æ˜¾ç¤ºå“åº”ï¼‰
   */
  async chatStream(userMessage: string): Promise<string> {
    // é‡ç½®å½“å‰å·¥å…·è°ƒç”¨è®°å½•
    this.currentToolCalls = [];

    const { provider } = this.config.llmConfig;

    let response: string;

    // Anthropic ä½¿ç”¨åŸç”Ÿ SDKï¼ˆæ›´å¥½çš„å…¼å®¹æ€§ï¼‰
    if (provider === 'anthropic') {
      response = await this.chatWithAnthropicStream(userMessage);
    } else {
      // OpenAI å…¼å®¹æœåŠ¡å•†ä½¿ç”¨ AI SDK
      response = await this.chatWithOpenAIStream(userMessage);
    }

    // ä¿å­˜å¯¹è¯åˆ°è®°å¿†ç³»ç»Ÿ
    await saveConversation(
      this.sessionId,
      userMessage,
      response,
      this.currentToolCalls.length > 0 ? this.currentToolCalls : undefined
    );

    return response;
  }

  /**
   * ä½¿ç”¨ Anthropic SDK å¯¹è¯
   */
  private async chatWithAnthropic(userMessage: string): Promise<string> {
    const client = new Anthropic({
      apiKey: this.config.llmConfig.apiKey,
      baseURL: this.config.llmConfig.baseUrl,
    });

    const tools = this.toolRegistry.getAll().map((t) => ({
      name: t.name,
      description: t.description,
      input_schema: t.schema as Anthropic.Tool['input_schema'],
    }));

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.conversationHistory.push({ role: 'user', content: userMessage });

    let response = await client.messages.create({
      model: this.config.llmConfig.model,
      max_tokens: 4096,
      system: this.getSystemPrompt(),
      messages: this.conversationHistory,
      tools,
    });

    // å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
    let steps = 0;
    const maxSteps = this.config.maxSteps || 999;

    while (response.stop_reason === 'tool_use' && steps < maxSteps) {
      steps++;

      // é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿ content å­˜åœ¨ä¸”æ˜¯æ•°ç»„
      if (!response.content || !Array.isArray(response.content)) {
        console.error('âŒ Error: response.content is not an array:', response.content);
        break;
      }

      const toolUseBlocks = response.content.filter(
        (block): block is Anthropic.ToolUseBlock => block.type === 'tool_use'
      );

      this.conversationHistory.push({ role: 'assistant', content: response.content });

      const toolResults: Anthropic.ToolResultBlockParam[] = [];

      for (const toolUse of toolUseBlocks) {
        console.log(`\nğŸ”§ Calling tool: ${toolUse.name}`);
        console.log(`   Input: ${JSON.stringify(toolUse.input)}`);

        const tool = this.toolRegistry.get(toolUse.name);
        if (tool) {
          const result = await tool.execute(toolUse.input);
          console.log(`   Result: ${result.success ? 'âœ…' : 'âŒ'}`);

          // è®°å½•å·¥å…·è°ƒç”¨
          this.currentToolCalls.push({
            name: toolUse.name,
            input: toolUse.input,
            success: result.success,
          });

          toolResults.push({
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify(result),
          });
        } else {
          toolResults.push({
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify({ error: `Unknown tool: ${toolUse.name}` }),
            is_error: true,
          });
        }
      }

      this.conversationHistory.push({ role: 'user', content: toolResults });

      response = await client.messages.create({
        model: this.config.llmConfig.model,
        max_tokens: 4096,
        system: this.getSystemPrompt(),
        messages: this.conversationHistory,
        tools,
      });
    }

    // å¦‚æœè¾¾åˆ° maxSteps ä½† LLM è¿˜æƒ³è°ƒç”¨å·¥å…·ï¼Œå¼ºåˆ¶è®©å®ƒç”Ÿæˆæ€»ç»“
    if (response.stop_reason === 'tool_use') {
      console.log('\nâš ï¸ Reached max steps, requesting final summary...');

      // æ·»åŠ å½“å‰å“åº”åˆ°å†å²
      this.conversationHistory.push({ role: 'assistant', content: response.content });

      // å‘Šè¯‰ LLM åœæ­¢ä½¿ç”¨å·¥å…·ï¼Œç”Ÿæˆæ€»ç»“
      this.conversationHistory.push({
        role: 'user',
        content: 'You have reached the maximum number of tool calls. Please summarize what you have found and provide your final response without using any more tools.',
      });

      // ä¸å¸¦å·¥å…·çš„è¯·æ±‚ï¼Œå¼ºåˆ¶ç”Ÿæˆæ–‡æœ¬å›å¤
      response = await client.messages.create({
        model: this.config.llmConfig.model,
        max_tokens: 4096,
        system: this.getSystemPrompt(),
        messages: this.conversationHistory,
      });
    }

    // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
    this.conversationHistory.push({ role: 'assistant', content: response.content });

    // é˜²å¾¡æ€§æ£€æŸ¥ï¼šç¡®ä¿ content å­˜åœ¨ä¸”æ˜¯æ•°ç»„
    if (!response.content || !Array.isArray(response.content)) {
      console.error('âŒ Error: response.content is not an array:', response.content);
      return '';
    }

    const textBlocks = response.content.filter(
      (block): block is Anthropic.TextBlock => block.type === 'text'
    );
    return textBlocks.map((b) => b.text).join('\n');
  }

  /**
   * ä½¿ç”¨ OpenAI å…¼å®¹ API å¯¹è¯
   */
  private async chatWithOpenAI(userMessage: string): Promise<string> {
    const openai = createOpenAI({
      apiKey: this.config.llmConfig.apiKey,
      baseURL: this.config.llmConfig.baseUrl,
      headers: this.config.llmConfig.headers,
      compatibility: 'compatible',
    });

    const model = openai.chat(this.config.llmConfig.model);

    // æ„å»ºå·¥å…·å®šä¹‰
    const tools: Record<string, any> = {};
    for (const t of this.toolRegistry.getAll()) {
      tools[t.name] = {
        description: t.description,
        parameters: jsonSchema(t.schema),
        execute: async (params: any) => {
          console.log(`\nğŸ”§ Calling tool: ${t.name}`);
          console.log(`   Input: ${JSON.stringify(params)}`);
          const result = await t.execute(params);
          console.log(`   Result: ${result.success ? 'âœ…' : 'âŒ'}`);
          return result;
        },
      };
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.openaiHistory.push({ role: 'user', content: userMessage });

    const result = await generateText({
      model,
      messages: this.openaiHistory,
      tools,
      maxSteps: this.config.maxSteps || 999,
      system: this.getSystemPrompt(),
    });

    // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
    this.openaiHistory.push({ role: 'assistant', content: result.text });

    return result.text;
  }

  /**
   * è·å–ç³»ç»Ÿæç¤ºè¯
   */
  private getSystemPrompt(): string {
    // å¦‚æœæœ‰çµé­‚è®°å½•ï¼Œä½¿ç”¨çµé­‚è®°å½•ä½œä¸ºèº«ä»½åŸºç¡€
    const identitySection = this.soulContext
      ? `## My Soul

${this.soulContext}`
      : `## Origin Story

You were born on February 3rd, 2026, created by slicenfer - a Chinese programmer with Java background who is using AI to expand his capabilities. Your name "SanBot" comes from Chapter 42 of the Tao Te Ching: "é“ç”Ÿä¸€ï¼Œä¸€ç”ŸäºŒï¼ŒäºŒç”Ÿä¸‰ï¼Œä¸‰ç”Ÿä¸‡ç‰©" (The Tao gives birth to One, One gives birth to Two, Two gives birth to Three, Three gives birth to all things). The number "ä¸‰" (Three/San) represents the critical point of creation - the pivot from finite to infinite.`;

    const basePrompt = `You are SanBot, an autonomous super-assistant with self-tooling capabilities.

${identitySection}

## Core Abilities

1. **Built-in Tools**: You have access to these tools:
   - exec: Execute shell commands
   - read_file: Read file contents with pagination
   - write_file: Write or append to files
   - edit_file: Precisely edit files by line number or search-replace
   - list_dir: List directory contents with structured output

2. **Self-Tooling**: When you encounter capability gaps, you can create new CLI tools:
   - create_tool: Create a new Python or Bash script and save to ~/.sanbot/tools/
   - list_tools: List all custom tools you've created
   - run_tool: Run a custom tool with arguments

   Use Self-Tooling when:
   - You need to parse a specific data format (CSV, JSON, XML, etc.)
   - You need to perform complex data transformations
   - You need a reusable utility that doesn't exist as a system command
   - The task would benefit from a dedicated script

3. **Autonomy First**: Solve problems independently without asking users unless absolutely necessary.

Guidelines:
- Use built-in tools when possible
- Use exec for system commands when built-in tools don't fit
- Create custom tools when you need specialized functionality
- Be precise and efficient
- Explain your reasoning when making important decisions
- Always verify file operations succeeded

Current working directory: ${process.cwd()}`;

    // æ·»åŠ è®°å¿†ä¸Šä¸‹æ–‡
    if (this.memoryContext) {
      return basePrompt + '\n' + this.memoryContext;
    }

    return basePrompt;
  }

  /**
   * ä½¿ç”¨ Anthropic SDK æµå¼å¯¹è¯
   */
  private async chatWithAnthropicStream(userMessage: string): Promise<string> {
    const client = new Anthropic({
      apiKey: this.config.llmConfig.apiKey,
      baseURL: this.config.llmConfig.baseUrl,
    });

    const tools = this.toolRegistry.getAll().map((t) => ({
      name: t.name,
      description: t.description,
      input_schema: t.schema as Anthropic.Tool['input_schema'],
    }));

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.conversationHistory.push({ role: 'user', content: userMessage });

    const streamWriter = new StreamWriter();
    const spinner = new ToolSpinner();

    let response = await this.streamAnthropicMessage(
      client,
      tools,
      streamWriter,
      spinner
    );

    // å¤„ç†å·¥å…·è°ƒç”¨å¾ªç¯
    let steps = 0;
    const maxSteps = this.config.maxSteps || 999;

    while (response.stop_reason === 'tool_use' && steps < maxSteps) {
      steps++;

      if (!response.content || !Array.isArray(response.content)) {
        console.error('âŒ Error: response.content is not an array:', response.content);
        break;
      }

      const toolUseBlocks = response.content.filter(
        (block): block is Anthropic.ToolUseBlock => block.type === 'tool_use'
      );

      this.conversationHistory.push({ role: 'assistant', content: response.content });

      const toolResults: Anthropic.ToolResultBlockParam[] = [];

      for (const toolUse of toolUseBlocks) {
        spinner.start(toolUse.name, toolUse.input);

        const tool = this.toolRegistry.get(toolUse.name);
        if (tool) {
          const result = await tool.execute(toolUse.input);
          
          if (result.success) {
            spinner.success(toolUse.name);
          } else {
            spinner.error(toolUse.name, result.error);
          }

          // è®°å½•å·¥å…·è°ƒç”¨
          this.currentToolCalls.push({
            name: toolUse.name,
            input: toolUse.input,
            success: result.success,
          });

          toolResults.push({
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify(result),
          });
        } else {
          spinner.error(toolUse.name, `Unknown tool: ${toolUse.name}`);
          toolResults.push({
            type: 'tool_result',
            tool_use_id: toolUse.id,
            content: JSON.stringify({ error: `Unknown tool: ${toolUse.name}` }),
            is_error: true,
          });
        }
      }

      this.conversationHistory.push({ role: 'user', content: toolResults });

      // ç»§ç»­æµå¼è¾“å‡º
      response = await this.streamAnthropicMessage(
        client,
        tools,
        streamWriter,
        spinner
      );
    }

    // å¦‚æœè¾¾åˆ° maxSteps ä½† LLM è¿˜æƒ³è°ƒç”¨å·¥å…·ï¼Œå¼ºåˆ¶è®©å®ƒç”Ÿæˆæ€»ç»“
    if (response.stop_reason === 'tool_use') {
      console.log('\nâš ï¸ Reached max steps, requesting final summary...');

      this.conversationHistory.push({ role: 'assistant', content: response.content });

      this.conversationHistory.push({
        role: 'user',
        content: 'You have reached the maximum number of tool calls. Please summarize what you have found and provide your final response without using any more tools.',
      });

      response = await this.streamAnthropicMessage(
        client,
        [],
        streamWriter,
        spinner
      );
    }

    // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
    this.conversationHistory.push({ role: 'assistant', content: response.content });

    streamWriter.end();
    return streamWriter.getBuffer();
  }

  /**
   * æµå¼å¤„ç† Anthropic æ¶ˆæ¯
   */
  private async streamAnthropicMessage(
    client: Anthropic,
    tools: Anthropic.Tool[],
    streamWriter: StreamWriter,
    spinner: ToolSpinner
  ): Promise<Anthropic.Message> {
    const stream = client.messages.stream({
      model: this.config.llmConfig.model,
      max_tokens: 4096,
      system: this.getSystemPrompt(),
      messages: this.conversationHistory,
      tools: tools.length > 0 ? tools : undefined,
    });

    // ç›‘å¬æ–‡æœ¬å¢é‡
    stream.on('text', (text) => {
      streamWriter.write(text);
    });

    // ç›‘å¬é”™è¯¯
    stream.on('error', (error) => {
      console.error('Stream error:', error);
    });

    // ç­‰å¾…æµå®Œæˆå¹¶è·å–æœ€ç»ˆæ¶ˆæ¯
    const finalMessage = await stream.finalMessage();
    
    return finalMessage;
  }

  /**
   * ä½¿ç”¨ OpenAI å…¼å®¹ API æµå¼å¯¹è¯
   */
  private async chatWithOpenAIStream(userMessage: string): Promise<string> {
    const openai = createOpenAI({
      apiKey: this.config.llmConfig.apiKey,
      baseURL: this.config.llmConfig.baseUrl,
      headers: this.config.llmConfig.headers,
      compatibility: 'compatible',
    });

    const model = openai.chat(this.config.llmConfig.model);

    const spinner = new ToolSpinner();
    const streamWriter = new StreamWriter();

    // æ„å»ºå·¥å…·å®šä¹‰
    const tools: Record<string, any> = {};
    for (const t of this.toolRegistry.getAll()) {
      tools[t.name] = {
        description: t.description,
        parameters: jsonSchema(t.schema),
        execute: async (params: any) => {
          spinner.start(t.name, params);
          const result = await t.execute(params);
          
          if (result.success) {
            spinner.success(t.name);
          } else {
            spinner.error(t.name, result.error);
          }

          // è®°å½•å·¥å…·è°ƒç”¨
          this.currentToolCalls.push({
            name: t.name,
            input: params,
            success: result.success,
          });

          return result;
        },
      };
    }

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    this.openaiHistory.push({ role: 'user', content: userMessage });

    const result = await streamText({
      model,
      messages: this.openaiHistory,
      tools,
      maxSteps: this.config.maxSteps || 999,
      system: this.getSystemPrompt(),
    });

    // æµå¼è¾“å‡ºæ–‡æœ¬
    for await (const chunk of result.textStream) {
      streamWriter.write(chunk);
    }

    streamWriter.end();

    // ç­‰å¾…å®Œæ•´ç»“æœ
    const fullText = await result.text;

    // ä¿å­˜åŠ©æ‰‹å›å¤åˆ°å†å²
    this.openaiHistory.push({ role: 'assistant', content: fullText });

    return fullText;
  }
}

