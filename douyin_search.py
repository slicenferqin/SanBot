#!/usr/bin/env python3
"""
æŠ–éŸ³æœç´¢å·¥å…· - ä½¿ç”¨ so.douyin.com æœç´¢é¡µé¢
åçˆ¬è™«è¾ƒå¼±ï¼Œé€‚åˆè·å–ç”¨æˆ·ä¿¡æ¯
"""

import asyncio
import json
import time
import re
from playwright.async_api import async_playwright
from datetime import datetime

class DouyinSearcher:
    def __init__(self, headless=False):
        self.headless = headless
        self.user_data_dir = "./douyin_session"
        
    async def search_user(self, keyword):
        """æœç´¢ç”¨æˆ·"""
        print(f"\n{'='*60}")
        print(f"ğŸ” æœç´¢æŠ–éŸ³ç”¨æˆ·: {keyword}")
        print(f"{'='*60}\n")
        
        async with async_playwright() as p:
            # å¯åŠ¨æµè§ˆå™¨ - æŒä¹…åŒ–ä¸Šä¸‹æ–‡
            browser = await p.chromium.launch_persistent_context(
                user_data_dir=self.user_data_dir,
                headless=self.headless,
                args=[
                    '--disable-blink-features=AutomationControlled',
                    '--no-first-run',
                    '--disable-infobars'
                ]
            )
            
            page = browser.pages[0] if browser.pages else await browser.new_page()
            
            # è®¾ç½®çœŸå® User-Agent
            await page.set_extra_http_headers({
                'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36'
            })
            
            try:
                # è®¿é—®æŠ–éŸ³æœç´¢é¡µé¢
                search_url = f"https://so.douyin.com/search?keyword={keyword}&source=normal_search&type=user"
                print(f"ğŸ“ è®¿é—®æœç´¢é¡µé¢: {search_url}")
                
                await page.goto(search_url, wait_until='networkidle', timeout=30000)
                print("âœ… é¡µé¢åŠ è½½æˆåŠŸ")
                
                # ç­‰å¾…å†…å®¹åŠ è½½
                await asyncio.sleep(3)
                
                # è·å–é¡µé¢å†…å®¹
                content = await page.content()
                
                # å°è¯•å¤šç§æ–¹å¼è·å–æ•°æ®
                print("\nğŸ” å°è¯•æå–æ•°æ®...")
                
                # æ–¹æ³•1: æŸ¥æ‰¾ script æ ‡ç­¾ä¸­çš„æ•°æ®
                script_pattern = r'<script[^>]*id="RENDER_DATA"[^>]*>(.*?)</script>'
                matches = re.findall(script_pattern, content)
                
                if matches:
                    print("âœ… æ‰¾åˆ° RENDER_DATA!")
                    for idx, match in enumerate(matches[:3]):  # åªå–å‰3ä¸ª
                        try:
                            # è§£ç æ•°æ®
                            decoded_data = bytes(match, 'utf-8').decode('unicode_escape')
                            # æå– JSON éƒ¨åˆ†
                            json_match = re.search(r'\{.*\}', decoded_data)
                            if json_match:
                                data = json.loads(json_match.group())
                                print(f"\nğŸ“Š æ•°æ®å— #{idx+1}:")
                                print(json.dumps(data, ensure_ascii=False, indent=2)[:1000])
                                
                                # å°è¯•æå–ç”¨æˆ·ä¿¡æ¯
                                self._extract_user_info(data)
                        except Exception as e:
                            print(f"âŒ è§£ææ•°æ®å— #{idx+1} å¤±è´¥: {e}")
                
                # æ–¹æ³•2: æˆªå›¾çœ‹çœ‹é¡µé¢å†…å®¹
                screenshot_path = f"douyin_search_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
                await page.screenshot(path=screenshot_path, full_page=True)
                print(f"\nğŸ“¸ é¡µé¢æˆªå›¾å·²ä¿å­˜: {screenshot_path}")
                
                # æ–¹æ³•3: ä¿å­˜å®Œæ•´ HTML ä¾›åˆ†æ
                html_path = f"douyin_search_{keyword}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
                with open(html_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                print(f"ğŸ“„ é¡µé¢ HTML å·²ä¿å­˜: {html_path}")
                
                # æ–¹æ³•4: æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
                if "éªŒè¯" in content or "å®‰å…¨éªŒè¯" in content:
                    print("\nâš ï¸ è§¦å‘äº†éªŒè¯é¡µé¢")
                    print("ğŸ’¡ è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®ŒæˆéªŒè¯ï¼Œç„¶åæŒ‰å›è½¦ç»§ç»­...")
                    input()
                    
                    # é‡æ–°è·å–å†…å®¹
                    await asyncio.sleep(2)
                    content = await page.content()
                
                # ç­‰å¾…ç”¨æˆ·æŸ¥çœ‹
                print(f"\nâ³ æµè§ˆå™¨å°†ä¿æŒæ‰“å¼€ 30 ç§’ï¼Œè¯·æ£€æŸ¥é¡µé¢å†…å®¹...")
                await asyncio.sleep(30)
                
            except Exception as e:
                print(f"âŒ æœç´¢å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
            
            finally:
                await browser.close()
    
    def _extract_user_info(self, data):
        """ä»æ•°æ®ä¸­æå–ç”¨æˆ·ä¿¡æ¯"""
        try:
            # å°è¯•ä¸åŒçš„æ•°æ®è·¯å¾„
            paths = [
                'data.data',
                'app.videoData', 
                'data',
                'result.data'
            ]
            
            user_info = None
            for path in paths:
                parts = path.split('.')
                current = data
                for part in parts:
                    if isinstance(current, dict) and part in current:
                        current = current[part]
                    else:
                        break
                else:
                    user_info = current
                    break
            
            if user_info:
                print(f"\nâœ… æ‰¾åˆ°ç”¨æˆ·ä¿¡æ¯:")
                print(json.dumps(user_info, ensure_ascii=False, indent=2)[:500])
                
        except Exception as e:
            print(f"âŒ æå–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")

async def main():
    searcher = DouyinSearcher(headless=False)
    await searcher.search_user("è´¾ä¹ƒäº®")

if __name__ == "__main__":
    asyncio.run(main())
